{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e1b992",
   "metadata": {},
   "source": [
    "# Structured Data\n",
    "\n",
    "## Key Concepts\n",
    "- Claude naturally adds explanatory text and markdown formatting around structured output\n",
    "- For applications needing raw data (JSON, code), this creates friction for users\n",
    "- Combine assistant message prefilling + stop sequences for clean output\n",
    "- Prefill with opening delimiter (e.g., \"```json\"), stop at closing delimiter (e.g., \"```\")\n",
    "- Claude thinks it already started a code block and continues with just the content\n",
    "- Stop sequence prevents Claude from adding closing markdown or explanations\n",
    "\n",
    "## Important Code Patterns\n",
    "- `add_assistant_message(messages, \"```json\")` - prefill with code block start\n",
    "- `chat(messages, stop_sequences=[\"```\"])` - stop before closing code block\n",
    "- `text.strip()` - remove extra newlines from response\n",
    "- `json.loads(text.strip())` - parse cleaned JSON string\n",
    "- Works for any structured format: Python code, CSV, bulleted lists\n",
    "- Identify what Claude wraps content in, use as prefill/stop combo\n",
    "\n",
    "## Best Practices\n",
    "- Use this technique when building apps that need copy-paste ready output\n",
    "- Prefill with the opening wrapper Claude would naturally use\n",
    "- Set stop sequence to the closing wrapper\n",
    "- Always clean/strip responses before parsing\n",
    "- Not just for JSON - applies to any structured data format\n",
    "- Essential for integrating AI-generated content into applications\n",
    "- Reduces user friction by eliminating manual content extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35951c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install anthropic python-dotenv\n",
    "\n",
    "# Imports\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from anthropic import Anthropic\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create client\n",
    "client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))\n",
    "model = \"claude-sonnet-4-0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7844d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user_message(messsages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": text}\n",
    "    messages.append(user_message)\n",
    "def add_assistant_message(messsages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)\n",
    "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "         \"model\": model,\n",
    "         \"max_tokens\": 1000,\n",
    "         \"messages\": messages,\n",
    "         \"temperature\": temperature,\n",
    "         \"stop_sequences\": stop_sequences\n",
    "    }\n",
    "    if system:\n",
    "         params[\"system\"] = system\n",
    "    message = client.messages.create(**params)\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41e92346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1, 2, '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = []\n",
    "add_user_message(\n",
    "    messages,\n",
    "    \"Count from 1 to 10\",\n",
    ")\n",
    "answer = chat(messages, stop_sequences=[\"5\", \"3, 4\"])\n",
    "answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df0cabac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\\n  \"Name\": \"OrderProcessingRule\",\\n  \"EventPattern\": {\\n    \"source\": [\"myapp.orders\"],\\n    \"detail-type\": [\"Order Placed\"]\\n  },\\n  \"Targets\": [\\n    {\\n      \"Id\": \"1\",\\n      \"Arn\": \"arn:aws:lambda:us-east-1:123456789012:function:ProcessOrder\"\\n    }\\n  ],\\n  \"State\": \"ENABLED\"\\n}\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = []\n",
    "\n",
    "add_user_message(messages, \"Generate a very short event bridge rule as json\")\n",
    "add_assistant_message(messages, \"'''json\")\n",
    "\n",
    "text = chat(messages, stop_sequences=[\"'''\"])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc33b9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'OrderProcessingRule',\n",
       " 'EventPattern': {'source': ['myapp.orders'], 'detail-type': ['Order Placed']},\n",
       " 'Targets': [{'Id': '1',\n",
       "   'Arn': 'arn:aws:lambda:us-east-1:123456789012:function:ProcessOrder'}],\n",
       " 'State': 'ENABLED'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json.loads(text.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
