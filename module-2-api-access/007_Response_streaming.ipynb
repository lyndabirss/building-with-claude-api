{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07576cee",
   "metadata": {},
   "source": [
    "# Response Streaming\n",
    "\n",
    "## Key Concepts\n",
    "- Streaming sends response chunks as they're generated (like ChatGPT's typing effect)\n",
    "- Improves perceived responsiveness for long responses\n",
    "- Uses Server-Sent Events (SSE) to stream data\n",
    "- Each chunk contains partial content that builds the full response\n",
    "- Must handle stream properly with try/finally or context managers\n",
    "\n",
    "## Important Code Patterns\n",
    "- `client.messages.stream()` - creates streaming response instead of `messages.create()`\n",
    "- `with client.messages.stream(...) as stream:` - context manager handles cleanup\n",
    "- `for text in stream.text_stream:` - iterate through text chunks as they arrive\n",
    "- `stream.get_final_message()` - get complete message object after streaming\n",
    "- Handle exceptions to ensure stream closes properly\n",
    "- Print chunks without newlines: `print(chunk, end=\"\", flush=True)`\n",
    "\n",
    "## Best Practices\n",
    "- Always use context manager or try/finally to ensure stream closes\n",
    "- Flush output after each chunk for real-time display\n",
    "- Streaming adds minimal overhead but greatly improves UX\n",
    "- Non-streaming is simpler for batch processing or when full response needed first\n",
    "- Consider streaming for user-facing applications, non-streaming for backend processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c949fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1041.65s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anthropic in ./venv/lib/python3.9/site-packages (0.75.0)\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.9/site-packages (1.2.1)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.9/site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.15 in ./venv/lib/python3.9/site-packages (from anthropic) (0.17.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./venv/lib/python3.9/site-packages (from anthropic) (2.12.5)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.9/site-packages (from anthropic) (0.12.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.9/site-packages (from anthropic) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.9/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in ./venv/lib/python3.9/site-packages (from anthropic) (0.28.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in ./venv/lib/python3.9/site-packages (from anthropic) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->anthropic) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->anthropic) (3.11)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.9/site-packages (from httpx<1,>=0.25.0->anthropic) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.9/site-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.2)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.41.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Users/lmbirss/Documents/coding-projects/building-with-claude-api/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "%pip install anthropic python-dotenv\n",
    "\n",
    "# Imports\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from anthropic import Anthropic\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create client\n",
    "client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))\n",
    "model = \"claude-sonnet-4-0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b218ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user_message(messsages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": text}\n",
    "    messages.append(user_message)\n",
    "def add_assistant_message(messsages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)\n",
    "def chat(messages, system=None):\n",
    "    params = {\n",
    "         \"model\": model,\n",
    "         \"max_tokens\": 1000,\n",
    "         \"messages\": messages,\n",
    "    }\n",
    "    if system:\n",
    "         params[\"system\"] = system\n",
    "    message = client.messages.create(**params)\n",
    "    return message.content[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3016be35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RawMessageStartEvent(message=Message(id='msg_01VHF3cGPF5petdAybRFUi1Z', content=[], model='claude-sonnet-4-20250514', role='assistant', stop_reason=None, stop_sequence=None, type='message', usage=Usage(cache_creation=CacheCreation(ephemeral_1h_input_tokens=0, ephemeral_5m_input_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=18, output_tokens=1, server_tool_use=None, service_tier='standard')), type='message_start')\n",
      "RawContentBlockStartEvent(content_block=TextBlock(citations=None, text='', type='text'), index=0, type='content_block_start')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text='F', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text='akeDB is a lightweight', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' in', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text='-memory database simulator', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' that generates', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' realistic', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' but', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' fictional datasets', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' for testing applications', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' without', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' ris', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text='king exposure', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' of sensitive', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' production', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' data.', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockStopEvent(index=0, type='content_block_stop')\n",
      "RawMessageDeltaEvent(delta=Delta(stop_reason='end_turn', stop_sequence=None), type='message_delta', usage=MessageDeltaUsage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=18, output_tokens=32, server_tool_use=None))\n",
      "RawMessageStopEvent(type='message_stop')\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "add_user_message(messages, \"Write a 1 sentence description of a fake database\")\n",
    "\n",
    "stream = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=1000,\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db75508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_017AKaJyRi28eVwjnN1vHtfr', content=[TextBlock(citations=None, text='The \"GlobalMind Database\" is a fictional cloud-based repository that claims to store and cross-reference the complete digital footprints, behavioral patterns, and predictive models of every internet user worldwide for advanced social analytics.', type='text')], model='claude-sonnet-4-20250514', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation=CacheCreation(ephemeral_1h_input_tokens=0, ephemeral_5m_input_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=18, output_tokens=49, server_tool_use=None, service_tier='standard'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with client.messages.stream(\n",
    "    model=model,\n",
    "    max_tokens=1000,\n",
    "    messages=messages\n",
    ") as stream:\n",
    "    for text in stream.text_stream:\n",
    "        # print(text, end=\"\")\n",
    "        pass\n",
    "    \n",
    "final_message = stream.get_final_message()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
