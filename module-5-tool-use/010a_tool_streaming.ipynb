{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Grained Tool Calling\n",
    "\n",
    "## Key Concepts\n",
    "- Tool streaming adds InputJsonEvent type with partial_json (chunk) and snapshot (cumulative JSON)\n",
    "- Default: API buffers chunks and validates complete top-level key-value pairs before sending\n",
    "- Buffering causes delays followed by bursts - chunks held until valid pair ready\n",
    "- Fine-grained mode disables API-side JSON validation for faster streaming\n",
    "- Fine-grained trade-off: immediate chunks vs. potential invalid JSON\n",
    "- Without fine-grained: validation delays but guaranteed valid JSON structure\n",
    "- With fine-grained: traditional streaming speed but must handle JSON errors\n",
    "\n",
    "## Important Code Patterns\n",
    "- Handle streaming event: `if chunk.type == \"input_json\": process chunk.partial_json or chunk.snapshot`\n",
    "- Enable fine-grained: `run_conversation(messages, tools=[schema], fine_grained=True)`\n",
    "- Error handling: `try: json.loads(chunk.snapshot) except json.JSONDecodeError: handle error`\n",
    "- Access partial data: `chunk.partial_json` for incremental piece\n",
    "- Access cumulative: `chunk.snapshot` for complete JSON so far\n",
    "- Invalid JSON examples: `\"word_count\": undefined` instead of proper number\n",
    "\n",
    "## Best Practices\n",
    "- Default mode sufficient for most applications (validation ensures correctness)\n",
    "- Enable fine-grained when: need real-time UI updates, want early partial processing, buffering delays hurt UX\n",
    "- Always implement robust JSON error handling with fine-grained mode\n",
    "- Fine-grained requires comfortable handling invalid/incomplete JSON\n",
    "- API validation catches errors in default mode (may wrap problematic values as strings)\n",
    "- Use fine-grained for responsiveness priority over guaranteed validity\n",
    "- Consider user experience impact of buffering delays vs. error handling complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env variables and create client\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic()\n",
    "model = \"claude-sonnet-4-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "\n",
    "def add_user_message(messages, message):\n",
    "    if isinstance(message, list):\n",
    "        user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": message,\n",
    "        }\n",
    "    else:\n",
    "        user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": message}],\n",
    "        }\n",
    "    messages.append(user_message)\n",
    "\n",
    "\n",
    "def add_assistant_message(messages, message):\n",
    "    if isinstance(message, list):\n",
    "        assistant_message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": message,\n",
    "        }\n",
    "    elif hasattr(message, \"content\"):\n",
    "        content_list = []\n",
    "        for block in message.content:\n",
    "            if block.type == \"text\":\n",
    "                content_list.append({\"type\": \"text\", \"text\": block.text})\n",
    "            elif block.type == \"tool_use\":\n",
    "                content_list.append(\n",
    "                    {\n",
    "                        \"type\": \"tool_use\",\n",
    "                        \"id\": block.id,\n",
    "                        \"name\": block.name,\n",
    "                        \"input\": block.input,\n",
    "                    }\n",
    "                )\n",
    "        assistant_message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": content_list,\n",
    "        }\n",
    "    else:\n",
    "        # String messages need to be wrapped in a list with text block\n",
    "        assistant_message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": message}],\n",
    "        }\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "\n",
    "def chat_stream(\n",
    "    messages,\n",
    "    system=None,\n",
    "    temperature=1.0,\n",
    "    stop_sequences=[],\n",
    "    tools=None,\n",
    "    tool_choice=None,\n",
    "    betas=[],\n",
    "):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop_sequences\": stop_sequences,\n",
    "    }\n",
    "\n",
    "    if tool_choice:\n",
    "        params[\"tool_choice\"] = tool_choice\n",
    "\n",
    "    if tools:\n",
    "        params[\"tools\"] = tools\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "\n",
    "    if betas:\n",
    "        params[\"betas\"] = betas\n",
    "\n",
    "    return client.beta.messages.stream(**params)\n",
    "\n",
    "\n",
    "def text_from_message(message):\n",
    "    return \"\\n\".join([block.text for block in message.content if block.type == \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool definition\n",
    "from anthropic.types import ToolParam\n",
    "\n",
    "save_article_schema = ToolParam(\n",
    "    {\n",
    "        \"name\": \"save_article\",\n",
    "        \"description\": \"Saves a scholarly journal article\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"abstract\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Abstract of the article. One short sentence max\",\n",
    "                },\n",
    "                \"meta\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"word_count\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"Word count\",\n",
    "                        },\n",
    "                        \"review\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Eight sentence review of the paper\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"word_count\", \"review\"],\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"abstract\", \"meta\"],\n",
    "        },\n",
    "    }\n",
    ")\n",
    "save_short_article_schema = ToolParam(\n",
    "    {\n",
    "        \"name\": \"save_article\",\n",
    "        \"description\": \"Saves a scholarly journal article\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"abstract\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Abstract of the article. One short sentence max\",\n",
    "                },\n",
    "                \"meta\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"word_count\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"Word count\",\n",
    "                        },\n",
    "                        \"review\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Review of paper. One short sentence max\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"word_count\", \"review\"],\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"abstract\", \"meta\"],\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def save_article(**kwargs):\n",
    "    return \"Article saved!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool Running\n",
    "import json\n",
    "\n",
    "\n",
    "def run_tool(tool_name, tool_input):\n",
    "    if tool_name == \"save_article\":\n",
    "        return save_article(**tool_input)\n",
    "\n",
    "\n",
    "def run_tools(message):\n",
    "    tool_requests = [block for block in message.content if block.type == \"tool_use\"]\n",
    "    tool_result_blocks = []\n",
    "\n",
    "    for tool_request in tool_requests:\n",
    "        try:\n",
    "            tool_output = run_tool(tool_request.name, tool_request.input)\n",
    "            tool_result_block = {\n",
    "                \"type\": \"tool_result\",\n",
    "                \"tool_use_id\": tool_request.id,\n",
    "                \"content\": json.dumps(tool_output),\n",
    "                \"is_error\": False,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            tool_result_block = {\n",
    "                \"type\": \"tool_result\",\n",
    "                \"tool_use_id\": tool_request.id,\n",
    "                \"content\": f\"Error: {e}\",\n",
    "                \"is_error\": True,\n",
    "            }\n",
    "\n",
    "        tool_result_blocks.append(tool_result_block)\n",
    "\n",
    "    return tool_result_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run conversation\n",
    "def run_conversation(messages, tools=[], tool_choice=None, fine_grained=False):\n",
    "    while True:\n",
    "        with chat_stream(\n",
    "            messages,\n",
    "            tools=tools,\n",
    "            betas=[\"fine-grained-tool-streaming-2025-05-14\"] if fine_grained else [],\n",
    "            tool_choice=tool_choice,\n",
    "        ) as stream:\n",
    "            for chunk in stream:\n",
    "                if chunk.type == \"text\":\n",
    "                    print(chunk.text, end=\"\")\n",
    "\n",
    "                if chunk.type == \"content_block_start\":\n",
    "                    if chunk.content_block.type == \"tool_use\":\n",
    "                        print(f'\\n>>> Tool Call: \"{chunk.content_block.name}\"')\n",
    "\n",
    "                if chunk.type == \"input_json\" and chunk.partial_json:\n",
    "                    print(chunk.partial_json, end=\"\")\n",
    "\n",
    "                if chunk.type == \"content_block_stop\":\n",
    "                    print(\"\\n\")\n",
    "\n",
    "            response = stream.get_final_message()\n",
    "\n",
    "        add_assistant_message(messages, response)\n",
    "\n",
    "        if response.stop_reason != \"tool_use\":\n",
    "            break\n",
    "\n",
    "        tool_results = run_tools(response)\n",
    "        add_user_message(messages, tool_results)\n",
    "\n",
    "        if tool_choice:\n",
    "            break\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll create and save a fake computer science article for you.\n",
      "\n",
      "\n",
      ">>> Tool Call: \"save_article\"\n",
      "{\"abstract\": \"This paper introduces a novel quantum-inspired algorithm for distributed graph partitioning that achieves logarithmic time complexity on sparse networks.\", \"meta\": {\n",
      "  \"word_count\": 4250,\n",
      "  \"review\": \"This paper presents an innovative approach to the graph partitioning problem by leveraging quantum-inspired heuristics in distributed computing environments. The authors demonstrate that their algorithm, QuPart, achieves O(log n) time complexity on sparse graphs with bounded degree, which represents a significant improvement over classical methods. The experimental evaluation on real-world social network datasets shows up to 40% reduction in edge cuts compared to METIS and other state-of-the-art partitioners. The theoretical analysis is rigorous and the proofs are well-constructed, though some assumptions about network topology may limit practical applicability. The distributed implementation using message-passing shows excellent scalability up to 1024 nodes. However, the paper could benefit from more discussion on memory overhead and communication costs. The quantum-inspired annealing process is particularly elegant and may have applications beyond graph partitioning. Overall, this is a strong contribution to the field that bridges quantum computing concepts with practical distributed algorithms.\"\n",
      "}}\n",
      "\n",
      "Done! I've created and saved a fake computer science article about a quantum-inspired algorithm for distributed graph partitioning. The article includes:\n",
      "\n",
      "- **Abstract**: A brief description of a novel algorithm called QuPart for graph partitioning with logarithmic time complexity\n",
      "- **Word count**: 4,250 words\n",
      "- **Review**: An eight-sentence peer review discussing the paper's contributions, strengths (improved complexity, good experimental results, rigorous analysis), and areas for improvement (memory overhead discussion, practical limitations)\n",
      "\n",
      "The article is now saved in the system!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'Create and save a fake computer science article'}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': \"I'll create and save a fake computer science article for you.\"},\n",
       "   {'type': 'tool_use',\n",
       "    'id': 'toolu_01VQTGshtZkru9fKj2LiFC4d',\n",
       "    'name': 'save_article',\n",
       "    'input': {'abstract': 'This paper introduces a novel quantum-inspired algorithm for distributed graph partitioning that achieves logarithmic time complexity on sparse networks.',\n",
       "     'meta': {'word_count': 4250,\n",
       "      'review': 'This paper presents an innovative approach to the graph partitioning problem by leveraging quantum-inspired heuristics in distributed computing environments. The authors demonstrate that their algorithm, QuPart, achieves O(log n) time complexity on sparse graphs with bounded degree, which represents a significant improvement over classical methods. The experimental evaluation on real-world social network datasets shows up to 40% reduction in edge cuts compared to METIS and other state-of-the-art partitioners. The theoretical analysis is rigorous and the proofs are well-constructed, though some assumptions about network topology may limit practical applicability. The distributed implementation using message-passing shows excellent scalability up to 1024 nodes. However, the paper could benefit from more discussion on memory overhead and communication costs. The quantum-inspired annealing process is particularly elegant and may have applications beyond graph partitioning. Overall, this is a strong contribution to the field that bridges quantum computing concepts with practical distributed algorithms.'}}}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'tool_result',\n",
       "    'tool_use_id': 'toolu_01VQTGshtZkru9fKj2LiFC4d',\n",
       "    'content': '\"Article saved!\"',\n",
       "    'is_error': False}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': \"Done! I've created and saved a fake computer science article about a quantum-inspired algorithm for distributed graph partitioning. The article includes:\\n\\n- **Abstract**: A brief description of a novel algorithm called QuPart for graph partitioning with logarithmic time complexity\\n- **Word count**: 4,250 words\\n- **Review**: An eight-sentence peer review discussing the paper's contributions, strengths (improved complexity, good experimental results, rigorous analysis), and areas for improvement (memory overhead discussion, practical limitations)\\n\\nThe article is now saved in the system!\"}]}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = []\n",
    "\n",
    "add_user_message(\n",
    "    messages,\n",
    "    \"Create and save a fake computer science article\",\n",
    ")\n",
    "\n",
    "run_conversation(\n",
    "    messages,\n",
    "    tools=[save_article_schema],\n",
    "    fine_grained=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
